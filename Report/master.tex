%\documentclass[11pt]{report}
%\usepackage[a4paper]{geometry}
\input{prelude}

%%%%%%%%%%%%%%%%%%
% BEGIN DOCUMENT %
%%%%%%%%%%%%%%%%%%

%\usepackage[final]{listings}

%\input{csvfiles}

\begin{document}

\maketitle
%\frontmatter
%\makedecl
\input{acknowledgement}
%\include{abstract}
%\mainmatter
%\setcounter{tocdepth}{3}
%\setcounter{secnumdepth}{3} dunno what this does.
{
  \hypersetup{linkcolor=black}
  \tableofcontents
  % Two times compilation
  %\listoffigures
  %\listoftables
   
}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Intro
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
%\section{Problem description and motivation} \todo{maybe remove this section}
Railway companies need to continuously and sufficiently maintain the train tracks and optimally detect defects in order to have a more punctual and more effective train system. However, the current system is expensive, time consuming and ineffective. That is, maintenance agents need to walk along tracks and check them for defects. For visualisation purposes, there is roughly 5200 km of rails in Switzerland which needs to be inspected by 40 experienced inspectors.


In order to cope with this issue, Swiss Federal Railways (SBB) has specifically built two new special diagnostic vehicles (SDV) designed for defect identification among other purposes. For this, accelerometers have been installed at the front and back of the vehicle to collect the signal responses from the wheel and the train track (see appendix \ref{figs:veh}).

A defect in train tracks can be seen as a discontinuity. As a train passes over this discontinuity, it will result in a perturbation that can be detected by sensors. It is our main assumption that each type of defect will have a specific signature that will allow its identification and classification. This is similar to the idea presented in \cite{Introduc31:online} about human activity recognition.

\section{Objective}
As the title implies, the objective of this project is to identify and classify rail surface defects. To do this, we aim to build an effective pipeline that takes information about defects as input and outputs a classification confidence for these defects. By succesfully identifying and classifying the defects, we take one step further towards reducing delays and making trains more punctual and reliable. The first step in this development consists of identification and classification, while the second step ultimately consists of future defect prediction.

\section{Defects}
Evidently, a defect can be seen as a deviation from the standard train track. For the exact defect type, SBB has self-constructed a database for the individual defect definitions \todo{is this a recognized system?}. See appendix \ref{app:report} for an example as to how this is done.
%Gleis	149.849086	(400, A-184063)	
%chienenzwischenlage	4.989620	(400, A-146358)	
%Bankett	1169.510537	(400, A-103213)

%Schwelle	0.000000	(400, A-103206)	
%Schwelle	0.000000	(400, A-118152)	
%Vignolschiene	0.000000	(400, A-231400)	
%Fahrbahn	0.000000	(400, A-233599)	

Generally, a defect is separated into two overarching types: range- and point-defects. I.e. a defect that is detected at a single point versus a defect that is detected at varying lengths.
\begin{figure}[H]
	\centering
	%\includegraphics[width = 0.49\textwidth]{imgs/defs/p(400,A-103206)0}
	%\caption{Defect ID: A-$103206$; Report set ID: $400$}
	\includegraphics[width = 0.2\textwidth]{imgs/defs/p(400,A-118152)0}
	\includegraphics[width = 0.38\textwidth]{imgs/defs/p(400,A-231400)0}
	\includegraphics[width = 0.38\textwidth]{imgs/defs/p(400,A-233599)0}
	\caption{Left, middle, right: Schwelle (A-$118152$), Fahrbahn (A-$233599$), Vignolschiene (A-$231400$). These have all been reported as defects (with subcategories) with a length equals to zero, and thus have been classified as point defects using our terminology. Parenthesis signifies defect ID and all pictures comes from SBB defect report set ID: $400$}
\end{figure}
%\vspace*{-1cm}
\begin{figure}[H]
	\centering
	%\includegraphics[width = 0.49\textwidth]{imgs/defs/p(400,A-103206)0}
	%\caption{Defect ID: A-$103206$; Report set ID: $400$}
	\includegraphics[width = 0.35\textwidth]{imgs/defs/r(400,A-184063)0}
	\includegraphics[width = 0.35\textwidth]{imgs/defs/r(400,A-184063)1}
	
	\includegraphics[width = 0.35\textwidth]{imgs/defs/r(400,A-146358)0}
	\includegraphics[width = 0.35\textwidth]{imgs/defs/r(400,A-146358)1}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[width = 0.35\textwidth]{imgs/defs/r(400,A-103213)0}
	\caption{Top, middle, bottom: Gleis-$149.8 m$ (A-$184063$), Schienenzwischenlage-$5.0 m$ (A-$146358$), Bankett-$1169.5 m$ (A-$231400$). These have all been reported as defects (with subcategories) with a length strictly greater than zero, and thus have been classified as range defects using our terminology. Parenthesis signifies defect ID and all pictures comes from SBB defect report set ID: $400$. Most of these range defects have two pictures likely to give more detail}
\end{figure}
\raggedbottom % to get of unnecessary vertical spacing
For this project, we have solely focused on the point defects for analysis, as this simplifies the problem statement. A point defect is perceived as a sharp signal response, whereas a range-defect is perceived over a greater time period. We thus disregard range-defects such that we do not have to deal with the extra, associated factors. \todo{See list of defect types in appendix?}


\section{Data}
The data has been collected and provided by SBB. Using their SDV, SBB has made trips back and forth to different cities in Switzerland in order to collect various data including but not limited to accelerometer data. After getting the data from SBB, it then goes through a processing pipeline (designed by Cyprien), after which the data can be manipulated with \verb|python| dataframes (from \verb|pd.DataFrame|). The accelerometer captures the accelerations at the XYZ-axes (along with the timestamps at each recording), of which we are only concerned with the Y-axis for the vertical pertubations for the accelerometer at the axle. See appendix \ref{figs:veh} for visualisations of the accelerometer placements on the SDV.

%\todo{make a table of the equipment and sample frequencies}

Furhtermore, the locations of the defects have to be retrieved from SBB's database. which were retrieved by Cyprien. \todo{Which data was worked on, put in tables, switches, ins joints and defects}

We need to define terminlogy of these: defects, ins joints, switches. In the following we will use entities as an umbrella term for the aforementioned track phenomenons.

\section{Code}
The code is written purely in python. To create neural network architectures, we are using: \verb|keras| along with \verb|tensorflow|. \verb|keras| is essentially a high-level neural networks library which runs on top of \verb|tensorflow|. It has consistent, a simple API and provides clear and actionable feedback upon user error. Models are easily made by connecting configurable building blocks together, with few restrictions \cite{TensorFl31:online}. The models were trained in \verb|Google Colab|, which is a web application provided by Google that enables users to run python code in the web browser with access to GPUs\footnote{\url{https://colab.research.google.com/notebooks/intro.ipynb}}. It is very similar to \verb|Anaconda's| \verb|Jupyter Notebooks|, except that \verb|Colab| runs in the browser, is collaborative and provides free usage of GPUs (meaning model training goes faster).\\


\noindent All the code can be found on github: \\
\url{https://github.com/Aiyualive/SemesterProject2.0}.\\

\noindent The specific model execution workflow can be found \verb|Colab|:\\
\url{https://colab.research.google.com/drive/12VBz_KrJxeyR_pjpkC87fewv5aMSEI5_}

%mainly uses pandas and stuff


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Design and implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Design and Implementation}

For the process of defect classification we designed the pipeline in \ref{fig:pipeline}. In the next sections, I would like to give an overview of how each step was implemented.
\begin{figure}[H]
	\centering
	\includegraphics[width = \textwidth]{imgs/pipeline}
	\caption{Primary pipeline}
	\label{fig:pipeline}
\end{figure}


%--> reevaluation| Realised that the results were not very good. So we need to visualise the data and look for separability to make a better model


\section{Shift of GPS timestamps}
The SDV has its GPS sensor installed at a specified location on the vehicle body. However, what we need to achieve is the position (covered distance) at each accelerometer at either sides of the GPS. Since the GPS sensor is sampled at a lower frequency compared to the accelerometers (20kHz vs 24kHz respectively), we first need to get the corresponding positions for each accelerometer sample. This is done by interpolation using the timestamps of the accelerometers and GPS. 

Depending on the direction of the vehicle we then subtract/add the offset between the accelerometers and the GPS sensor with regard to the position of these sensors on the vehicle body. \todo{insert drawing of how it is calculated?}

\section{Peak windows}
Retrieving the signal response around the defect location forms a crucial aspect in the overarching pipeline. The goal of this step is to, around each defect, create a "window" containing accelerometer accelerations of a specified time length -- wherein Within the highest acceleration recording around is found in the center. As a result, all of these windows would be uniform in the sense that they are all centered according to the highest recording of a defect. It is then assumed that each window forms the signature of each track entity. 

Since we are assuming that each track entity is identified by a well-formed peak, we first need to find this peak within a reasonable offset from the defect location, after which we center around that within another reasonable offset. 

In the code, this is done by defining two parameters: \verb|find_peak_offset = 1| and \verb|window_offset = 0.5|. I.e. given a defect timestamp, we search for the highest acceleration recording that has occured $1$ second after and $1$ second before the defect timestamp. Once the peak has been found, we then center it in a $1$ second window ($0.5$ sec on each side). \todo{insert a drawing of how this works?}

\section{Entity library}
The peak windows arguably forms the central feature of the defect library. However, from domain knowledge, other features like speed also needs to be considered for our neural network. Apart from the peak windows, we have also extracted a variety of relevant features that might be useful for classifcation. These include \todo{list, and how was it implemented}.

some can be extracted directly by the original dataframe, some needs some processing.

talk about only analysing point defects

show a few entity signals and their features, appendix for more signals? 

refer to the defects presented in introduction

\section{Classification}
We have created a primary \verb|NN| class (short for neural network) along with a \verb|ModelMaker| class. The former does everything from pre-processing the data to evaluating the used model. The latter, as the name suggests, is utlised for creating and using different models, which is useful as we can keep track of how the models have been modified and improved. 

\subsection{NN class}
To make a classification, we first need to select the relevant features. Then we simply feed the features into an \verb|NN| object, where the API of the \verb|NN| class can be called for classification. The usage of the \verb|NN| class is demonstrated below in \ref{tab:nnclass}.


\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l p{0.7\linewidth}}\noalign{\global\arrayrulewidth=0.3mm} 
	\hline 
	\multicolumn{2}{c}{\textbf{API of NN class}}
		\\ \hline  
		\noalign{\global\arrayrulewidth=0.05mm}
		\verb|__init__()|                  & initialises a \verb|NN| object\\ \hline
		\verb|prepare_data()|            & pre-process data, this includes standardisation of data\\ \hline
		\verb|make_model()|              & uses \verb|ModelMaker| class to select a model \\ \hline
		
		\verb|fit()|			         & trains the model\\ \hline
		\verb|classify()|			     & trains the model\\ 
		\noalign{\global\arrayrulewidth=0.3mm}
		\hline
	\end{tabular}
	\caption{To train a model, these functions needs to be called sequentially}\label{tab:nnclass}
\end{table}

\begin{table}[H]
	\label{other}
	\centering
	\small
	\begin{tabular}{l p{0.6\linewidth}}\noalign{\global\arrayrulewidth=0.3mm} \hline
	\multicolumn{2}{c}{\textbf{Other useful API functions}}
		\\ \hline 
		\noalign{\global\arrayrulewidth=0.05mm}
		\verb|measure_performance()|     & currently only done on validation data \\ \hline
		\verb|plot_metrics()|            & plots the metrics \\ \hline
		\verb|plot_confusion_matrix()|   & plots the confusion matrix\\ \hline
		\verb|load_weights()|            & \\ \hline
		\verb|load_model_()|            & \\ \hline
		\verb|save_history()|            & \\ \hline
		\verb|save_model()|              & \\ \hline
		\verb|save_classification_to_csv()| & \\ \hline
		\noalign{\global\arrayrulewidth=0.3mm}
		\hline \hline
		\verb|run_experiment()|          & evaluates the given model for a number of repetitions\\ 
		\noalign{\global\arrayrulewidth=0.3mm}
		\hline
	\end{tabular}
	\caption{f}
\end{table}
\raggedbottom % To get rid of weird spacing
%\todo{insert into appendix?}

\subsection{ModelMaker class}
See example of this in next chapter. \todo{todo}

Explain each layer?


\section{Visualisation}
Finally, after evaluating the results (results can be seen in the next section) from the neural network, we have not achieved any significant results. Arguably, the visualisations of class separability should have been handled first. However, the previous steps took the majority of the time.\todo{todo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
Here we will present the results and discuss the findings herein.


\section{Models}
\begin{table}[H]
	\centering
	\captionof{table}{Table Title} \label{tab:title2} 
	\begin{tabular}{|c|c|c| c|} \hline
		\textbf{Layer} & \textbf{Output Shape } & \textbf{Number of params} \\ \hline \hline 
		Synthetic data & 2000 &  9  \\ \hline 

	\end{tabular}
	\par \bigskip Dataset formats
	\label{datasets}
\end{table}

\url{http://alexlenail.me/NN-SVG/AlexNet.html}

\section{Model evaluation}
In this section we evaluate our model with regard to a variety of metrics: 
\begin{itemize}
	\item loss
	\item accuracy
	\item true positives
	\item false positives
	\item true negatives
	\item false negatives
	\item precision
	\item recall
	\item auc
\end{itemize}
Insert explanation of each metric\todo{just do one model at a time and show their metrics}
\begin{table}[H]
	\centering
\begin{tabular}{|lcccc|}
	\hline
	\backslashbox{run \#}{Metrics}
&{Model1}&{ClaveVectors}&{MNIST-bin-digits}&{MNIST-all-digits} \\\hline\hline
	1 &  & 61.355 & 3212.497 & 2454.585 \\ \hline
	2 & 16.568 & 62.396 & 3346.047 & 2782.271 \\ \hline
	3 & 14.362 & 59.282 & 2908.446 & 2618.519 \\ \hline
	4 & 13.85 & 62.193 & 3043.189 &  2600.233 \\ \hline
	5 & 13.755 & 61.024 & 3309.422 & 2470.139 \\ \hline
	6 & 12.218 & 58.531 & 3192.178 & 2823.685 \\ \hline
	7 & 12.232 & 60.187 & 3287.289 & 2452.566 \\ \hline
	8 & 13.346 & 59.398 & 3026.486 & 2810.943 \\ \hline
	9 & 11.433 & 61.892 & 3127.583 & 2528.202 \\ \hline
	10 & 11.63 & 60.925 & 3018.402 & 2746.729 \\ \hline
\end{tabular}
	\caption{Experiment result}
\end{table}


\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|} \hline
		\textbf{Defect Type} & $2$ \\ \hline
	\end{tabular}
	\caption{Entity distribution, different defect types and class distributions}
\end{table}



\section{Visualisation of class clustering}
insert the pca plots

\section{Discussion}
Data amount, could self-engineer data. 

should have done visualisation first, if we have clear cluster separation, applying a neural network would be a bit exaggerated. And in that case, we could opt for a simple multi class support vector machine from the \verb|sklearn| library. However, using \verb|tensorflow| was the plan from the get-go as it is more industrially-applicable, so we disregarded simpler methods.




%I tried to increase the outliers, but this was a hugely naive approach

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Conclusion and future work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and future work}

\section{Conclusion}
Results were quite mediocre, but has a lot of room for improvement. I am sure that given more time I would be able to explore and evaluate the results further.

how good is the foundation to move onwards with further research
\section{Future work}

\begin{itemize}
	\item Might be interesting to also consider the XZ-axes.
	\item range defects
	\item tune the peak finding parameters
	\item track entity dependent/specific window offsets
	\item we must not set the findpeakoffset too high
	\item Questions, what if you want to use multiple features with 1 CNN
	\item I have participated in ETH Hatchery (ref), where our team build a prototype with a model train. We let the model train drive on the track with self-engineered defects.

\end{itemize}

\newpage
\section{TODO}
\begin{itemize}
	\item get percentage of each class in the validation set
	\item create an average of the model ie run model for more times
	\item add speed as a feature
	\item what does each filter do? what is kernel size?
	\item very fast speed, overlap between switch and ins, old vs new rail, ax1 arrow 2 arrow 3 arrow 4
	\item 3D plots?
	\item change the defect library to use pandas instead?
	\item visualise what the network is doing using Harry's code
	\item use speed as a feature also
	\item be consistent with function naming and variable names: function names with underscore and variable names with camelcase
	\item Which type of defects are we actually working with, we can see that it does good at the switches and ins joints, but no chance with the defects
	\item we should instead call it an entity library -- make up your mind
	\item try only with defects and no ins and switches
	\item separate all the axle channels and train on them
	\item try to use low pass filter
	\item get better results
	\item we dont need non-defects for defect classification, we could just input something else and make sure that it is not a defect
	\item a specifc defect type vs ins joint vs switch
	\item we did not consider severity
	\item which track entities are we actually analysing
\end{itemize}

\bibliography{master}
%\todo{New paper with train}

\newpage
\cleardoublepage
\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Appendix introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

\section{Vehicle and accelerometer placements}
\label{figs:veh}
\begin{figure}[H]
	\centering
	\includegraphics[width = 0.58\textwidth]{imgs/veh0}
	\label{fig:veh0}
	
	\includegraphics[width = 0.58\textwidth]{imgs/veh1}
	\label{fig:veh1}
	
	\includegraphics[width = 0.58\textwidth]{imgs/veh2}
	\caption{These figures have been provided by Cyprien's folder of SBB documents. They show the accelerometer placements. For this project we have only considered axle number 4 in the third figure.}
	\label{fig:veh2}
\end{figure}

\section{SBB defect report example}
\label{app:report}
\begin{figure}[H]
	\centering
	\includegraphics[width = 0.9\textwidth]{imgs/defs/rep0}
	\caption{}
	\includegraphics[width = 0.9\textwidth]{imgs/defs/rep1}
	\caption{A typical report for an arbitrary defect usually contains one description page followed by its picture(s)}
	\label{fig:veh2}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Appendix implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
\begin{table}[H]
	\centering
	\begin{tabular}{l p{0.35\linewidth}} \hline
	\multicolumn{2}{c}{{\large \textbf{Functions in NN class}}}
		\\ \hline  
		prepare data      &  \\ \hline
	\end{tabular}
\end{table}
\chapter{Results}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|} \hline
		\textbf{Latent Dimension} & $2$ \\ \hline
		\textbf{Shape} & 8 $\times$ $8$ \\ \hline
		\textbf{Latent Points} &  $64$\\ \hline
		\textbf{Dist. Mixtures} &  Bernoulli\\ \hline \hline
		\textbf{Regularisation $\alpha$ } & $0.001$ \\ \hline
	\end{tabular}
	\hspace*{0.5cm}
	\begin{tabular}{|l|c|} \hline
		\textbf{RBF Dimension} & $2$ \\ \hline
		\textbf{RBF grid}  & $4\times4$ \\ \hline 
		\textbf{RBF centres} & $16$ \\ \hline
		\textbf{Basis function} & Gaussian \\ \hline
	    \textbf{Widths $\bm{\sigma}$} & $1.0$\\ \hline
	\end{tabular}
	\caption{The parameters for the latent model and the RBF neural network. Distribution mixtures and basis functions cannot be altered as our implementation is specific for the Bernoulli GTM version}
	\label{eval:model}
\end{table}


%\label{code}
%\inputminted[linenos, fontsize = \scriptsize]{python}{../src/utils/defect_utils.py}

\end{document}
