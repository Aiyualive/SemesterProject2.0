%\documentclass[11pt]{report}
%\usepackage[a4paper]{geometry}
\input{prelude}

%%%%%%%%%%%%%%%%%%
% BEGIN DOCUMENT %
%%%%%%%%%%%%%%%%%%

%\usepackage[final]{listings}

%\input{csvfiles}

\begin{document}

\maketitle
%\frontmatter
%\makedecl
\input{acknowledgement}
%\include{abstract}
%\mainmatter
%\setcounter{tocdepth}{3}
%\setcounter{secnumdepth}{3} dunno what this does.
{
  \hypersetup{linkcolor=black}
  \tableofcontents
  % Two times compilation
  %\listoffigures
  %\listoftables
   
}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Intro
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
%%%%%%%%%%% PARSER %%%%%%%%%%%
\section{Problem description and motivation} \todo{maybe remove this section}
Railway companies need to continuously and sufficiently maintain the train tracks and optimally detect defects in order to have a more punctual and more effective train system. However, the current system is expensive, time consuming and ineffective. That is, maintenance agents need to walk along tracks and check them for defects. For visualisation purposes, there is roughly 5200 km of rails in Switzerland which needs to be inspected by 40 experienced inspectors.


In order to cope with this issue, Swiss Federal Railways (SBB) has specifically built two new special diagnostic vehicles (SDV) designed for defect identification among other purposes. For this, two accelerometers have been installed at the front and back of the vehicle to collect the signal responses from the wheel and the train track
\todo{insert picture, mention boogey?}

A defect in train tracks can be seen as a discontinuity. As a train passes over this discontinuity, it will result in a perturbation that can be detected by sensors. It is our main assumption that each type of defect will have a specific signature that will allow its identification and classification. This is similar to the idea presented in \todo{https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf}

By succesfully identifying and classifying the defects, we take one step further towards reducing delays and making trains more punctual and reliable. The first step in this process consists of identification and classification, while the second step consists of future defect prediction.

\section{Objective}
As the title implies, the objective of this project is to identify and classify rail surface defects. 

apply machine learning techniques on the problem

\section{Defects}
Evidently, a defect can be seen as a deviation from the standard train track. For the exact defect type, SBB has self-constructed a database for the individual defect definitions \todo{is this a recognized system?}. Here is a few examples: \todo{insert pictures}


Generally, a defect is separated into two overarching types: range- and point-defects. I.e. a defect that is detected at a single point versus a defect that is detected at varying lengths -- e.g. \todo{give example}.

For this project, we have solely focused on the point defects for analysis, as this simplifies the problem statement. \todo{show signal types?}. A point defect is perceived as a sharp signal response, whereas a range-defect is perceived over a greater time period. We thus disregard range-defects such that we do not have to deal with the extra, associated factors. 

\todo{See list of defect types in appendix?}


\section{Data}
The data has been collected and provided by SBB. Using their SDV, SBB has made trips back and forth to different cities in Switzerland in order to collect various data including but not limited to accelerometer data. After getting the data from SBB, it then goes through a processing pipeline (designed by Cyprien), after which the data can be manipulated with \verb|python| dataframes (from \verb|pd.DataFrame|). The accelerometer captures the accelerations at the XYZ-axes (along with the timestamps at each recording), of which we are only concerned with the Y-axis for the vertical pertubations.

\todo{make a table of the equipment and sample frequencies}

Furhtermore, the locations of the defects have to be retrieved from SBB's database. which were retrieved by Cyprien.


\todo{Which data did I work on, put in tables, switches, ins joints and defects}

We need to define terminlogy of these: defects, ins joints = 
in the following we will use defect as an umbrella term for these entities.

\section{Code}
The code is written purely in python. The code can be found on github: \\
\url{https://github.com/Aiyualive/SemesterProject2.0}.

\todo{Brief explanation of the code?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Design and implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Design and Implementation}

For the process of defect classification we employed the following pipeline:
\todo{insert pipeline picture}

In the following, I would like to give an overview of how these was implemented

%\verb|signal --> shift GPS timestamps --> localise defects --> create a library of peak windows --> feed to convolutional NN --> reevaluation| Realised that the results were not very good. So we need to visualise the data and look for separability to make a better model

\todo{which track entities are we actually analysing}
\todo{show a few defects and their signals} 
\todo{appendix for more signals?}

\section{Shift of GPS timestamps}
The SDV has its GPS sensor installed at a specified location on the vehicle body. However, what we need to achieve is the position (covered distance) at each accelerometer at either sides of the GPS. Since the GPS sensor is sampled at a lower frequency compared to the accelerometers, we first need to get the corresponding positions for each accelerometer sample. This is done by interpolation using the timestamps of the accelerometers and GPS. 

Depending on the direction of the vehicle we then subtract/add the offset between the accelerometers and the GPS sensor with regard to the position of these sensors on the vehicle body.

\todo{insert drawing of how it is calculated?}

\section{Peak windows}
Retrieving the signal response around the defect location forms a crucial aspect in the overarching pipeline. The goal of this step is to, around each defect, create a "window" containing accelerometer accelerations of a specified time length -- wherein Within the highest acceleration recording around is found in the center. As a result, all of these windows would be uniform in the sense that they are all centered according to the highest recording of a defect. It is then assumed that each window forms the signature of each track entity. 

Since we are assuming that each track entity is identified by a well-formed peak, we first need to find this peak within a reasonable offset from the defect location, after which we center around that within another reasonable offset. 

In the code, this is done by defining two parameters: \verb|find_peak_offset = 1| and \verb|window_offset = 0.5|. I.e. given a defect timestamp, we search for the highest acceleration recording that has occured $1$ second after and $1$ second before the defect timestamp. Once the peak has been found, we then center it in a $1$ second window ($0.5$ sec on each side).

\todo{insert a drawing of how this works?}


\section{Neural network architecture}
Using tensorflow, we then feed these windows into our neural network architecture as seen in listing. 
\todo{insert table}

Trained a neural network, although we were only able to achieve max

Create the models and train it 

Based on the analysis we

\section{Visualisation}
This step should have been done first

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
Here we will present the results and discuss the findings herein.

\section{Results}
\todo{insert table for different architectures -- insert in previous chapter?} get the bachelor thesis for reference.

\section{Discussion}
I tried to increase the outliers, but this was a hugely naive approach

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Conclusion and future work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and future work}

\section{Conclusion}

\section{Future work}

\begin{itemize}
	\item Might be interesting to also consider the XZ-axes.
	\item range defects
	\item tune the peak finding parameters
	\item track entity dependent/specific window offsets
	\item we must not set the findpeakoffset too high
\end{itemize}

\newpage
\section{TODO}
\begin{itemize}
	\item very fast speed, overlap between switch and ins, old vs new rail, ax1 arrow 2 arrow 3 arrow 4
	\item 3D plots?
	\item change the defect library to use pandas instead?
	\item visualise what the network is doing using Harry's code
	\item use speed as a feature also
	\item be consistent with function naming and variable names
	\item 
\end{itemize}


\newpage
\section{Notes}


whats this
\begin{minted}{python}
def conv(df):
    """
    has to be series
    """
    return np.vstack([v for v in df])

dup_ins = s_features.ins_joints.copy()[['accelerations']]
dup_swi = s_features.switches.copy()[['accelerations']]
dup_def = s_features.defects.copy()[['accelerations']]

dup_ins['accelerations'] = np.sum(conv(dup_ins.accelerations),1)
dup_swi['accelerations'] = np.sum(conv(dup_swi.accelerations),1)
dup_def['accelerations'] = np.sum(conv(dup_def.accelerations),1)

# s_features.ins_joints[['vehicle_speed(m/s)', 'Axle', 'campagin_ID']].duplicated() or

idx_ins = dup_ins.accelerations.duplicated()
idx_swi = dup_swi.accelerations.duplicated()
idx_def = dup_def.accelerations.duplicated()
new_ins = s_features.ins_joints[~idx_ins]
new_swi = s_features.switches[~idx_swi]
new_def = s_features.switches[~idx_def]

print("Duplcated samples: ", len(dup_ins) - len(new_ins))
print("Duplcated samples: ", len(dup_swi) - len(new_swi))
print("Duplcated samples: ", len(dup_def) - len(new_def))

# Load weight example 
# Could just save entire model and then load entire model
# Could also make this into a function
clf2 = NN(N_FEATURES, N_CLASSES)
clf2.prepare_data(X, y)
clf2.make_model2()
clf2.load_weights('model_01-12-2019_150004.hdf5')
clf2.predict() ### on validation set
clf2.measure_performance(accuracy_score)
\end{minted}

Test sample
\begin{minted}{python}
ii = pd.DataFrame([
    [np.array([1,2]),2], 
    [np.array([1,2]),2], 
    [np.array([1,2]),2]])
    
    
x = a
[u,I,J] = unique(x, 'rows', 'first')
hasDuplicates = size(u,1) < size(x,1)
ixDupRows = setdiff(1:size(x,1), I)
dupRowValues = x(ixDupRows,:)

s_features.ins_joints.timestamps[:2].duplicated()
\end{minted}

\chapter{Appendix}
\todo{Figure out references}
\todo{New paper with train}

\newpage
\cleardoublepage
\appendix
\chapter{Appendix}
\label{code}
\inputminted[linenos, fontsize = \scriptsize]{haskell}{../src/utils/defect_utils.py}

\end{document}
